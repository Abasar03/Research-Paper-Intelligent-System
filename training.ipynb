{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzj3oGU_gzQe",
        "outputId": "1c92cd33-2bc2-47eb-8fbd-b0431af6b257"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import math\n",
        "import re\n",
        "import pickle\n",
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import CrossEntropyLoss, MSELoss\n",
        "from collections import Counter\n",
        "from tqdm import tqdm\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfTCXdqy7G8j",
        "outputId": "03361b99-eb08-43e9-f0bc-6b84a149ab84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset loaded: (80318, 33)\n",
            "Columns: ['paperID', 'venue', 'year', 'openAccessPdf', 'url', 'authors', 'referenceCount', 'title', 'abstract', 'conclusion', 'Chatgpt Response', 'Key Takeaways', 'Importance', 'Model/Method Proposed', 'Performance', 'Effectiveness', 'Future Works', 'Sentiment', 'Sentiment Score', 'combined', 'combined_keywords', 'response_keywords', 'future_work_keywords', 'capped_keywords', 'field', 'future_work_cleaned', 'abstract_cleaned', 'method_proposed_cleaned', 'conclusion_cleaned', 'gap_corpus', 'gap_sentences', 'contextual_gaps', 'domain_gaps']\n",
            "\n",
            "Sample gap corpus:\n",
            "[\"[ABSTRACT] face anti-spoofing approach based on domain generalization (dg) has drawn growing attention due to its robustness for unseen scenarios. existing dg methods assume that the domain label is known. however, in real-world applications, the collected dataset always contains mixture domains, where the domain label is unknown. in this case, most of existing methods may not work. further, even if we can obtain the domain label as existing methods, we think this is just a sub-optimal partition. to overcome the limitation, we propose domain dynamic adjustment meta-learning (d$^2$am) without using domain labels, which iteratively divides mixture domains via discriminative domain representation and trains a generalizable face anti-spoofing with meta-learning. specifically, we design a domain feature based on instance normalization (in) and propose a domain representation learning module (drlm) to extract discriminative domain features for clustering. moreover, to reduce the side effect of outliers on clustering performance, we additionally utilize maximum mean discrepancy (mmd) to align the distribution of sample features to a prior distribution, which improves the reliability of clustering. extensive experiments show that the proposed method outperforms conventional dg-based face anti-spoofing methods, including those utilizing domain labels. furthermore, we enhance the interpretability through visualization. [METHOD] ['d$^2$am (domain dynamic adjustment meta-learning)', 'domain representation learning module (drlm)', 'instance normalization for domain feature', 'maximum mean discrepancy (mmd) for aligning sample feature distribution'] [FUTURE_WORK] ['further enhance interpretability and visualization', 'explore applications to other domains beyond face anti-spoofing'] [CONCLUSION] conclusion:as shown in figure 3, tables 1 and2, our method outperforms all state-of-the-art methods under most of tasks. we make the following observations from the results. (1) dg-based face anti-spoofing methods perform better than ablation study we perform ablation study to verify the efficacy of each component. several observations can be made from table 3. (1) d 2 am w/o d means that d 2 am randomly selects meta-train and meta-test from mixture domains, and its performance is worse than d 2 am w/ d, which utilizes domain label as existing methods. this is because there is no domain shift between the randomly selected domains. hence, we think it is important to simulate difficult and abundant domain shift scenarios for meta-learning. ( in this paper, to the best of our knowledge, this is the first wok to address mixture domain face anti-spoofing, where the domain label is unknown. specifically, we design the d 2 am, which iteratively clusters mixture domains via discriminative domain representation and trains a generalizable feature extractor by meta-learning. a drlm and mmdbased regularization are designed for better dynamic adjustment to simulate more difficult and abundant domain shift scenes. comprehensive experiments show that d 2 am outperforms conventional dg-based face anti-spoofing methods, including those utilizing domain labels. furthermore, we enhance the interpretability through visualization.\"\n",
            " \"[ABSTRACT] various social situations entail a collective risk. a well-known example is climate change, wherein the risk of a future environmental disaster clashes with the immediate economic interest of developed and developing countries. the collective-risk game operationalizes this kind of situations. the decision process of the participants is determined by how good they are in evaluating the probability of future risk as well as their ability to anticipate the actions of the opponents. anticipatory behavior contrasts with the reactive theories often used to analyze social dilemmas. our initial work can already show that anticipative agents are a better model to human behavior than reactive ones. all the agents we studied used a recurrent neural network, however, only the ones that used it to predict future outcomes (anticipative agents) were able to account for changes in the context of games, a behavior also observed in experiments with humans. this extended abstract aims to explain how we wish to investigate anticipation within the context of the collective-risk game and the relevance these results may have for the field of hybrid socio-technical systems. [METHOD] ['using recurrent neural networks for agents in the collective-risk game.', 'contrasting anticipatory behavior with reactive theories in social dilemmas.'] [FUTURE_WORK] ['explore further applications of anticipatory behavior in complex social scenarios.', 'investigate the impact of different network architectures on agent decision-making.']\"\n",
            " \"[ABSTRACT] adverse drug reaction (adr) is a major burden for patients and healthcare industry. it usually causes preventable hospitalizations and deaths, while associated with a huge amount of cost. traditional preclinical in vitro safety profiling and clinical safety trials are restricted in terms of small scale, long duration, huge financial costs and limited statistical signifi- cance. the availability of large amounts of drug and adr data potentially allows adr predictions during the drugs’ early preclinical stage with data analytics methods to inform more targeted clinical safety tests. despite their initial success, existing methods have trade-offs among interpretability, predictive power and efficiency. this urges us to explore methods that could have all these strengths and provide practical solutions for real world adr predictions. we cast the adr-drug relation structure into a three-layer hierarchical bayesian model. we interpret each adr as a symbolic word and apply latent dirichlet allocation (lda) to learn topics that may represent certain biochemical mechanism that relates adrs with drug structures. based on lda, we designed an equivalent regularization term to incorporate the hierarchical adr domain knowledge. finally, we developed a mixed input model leveraging a fast collapsed gibbs sampling method that the complexity of each iteration of gibbs sampling proportional only to the number of positive adrs. experiments on real world data show our models achieved higher prediction accuracy and shorter running time than the state-of-the-art alternatives. [METHOD] ['three lda-based models for adr prediction.', 'a three-layer hierarchical bayesian model casting the adr-drug relation structure.', 'use of lda to learn topics representing biochemical mechanisms linking drug structures to adrs.', 'introduction of an equivalent regularization term based on hierarchical adr domain knowledge.', 'development of a mixed input model with fast collapsed gibbs sampling, enabling higher prediction accuracy and shorter running time.'] [FUTURE_WORK] ['improvement of the medical ontology system with real-world evidence.', 'addressing issues related to false-negative predictions.'] [CONCLUSION] conclusion:in this paper, we presented three lda-based models for adr prediction. the approach learns a hidden topic layer that may relate to biochemical mechanisms that link drug structures to adrs. moreover, the mixed input model has the best combination of prediction performance and training efficiency. experiments show that all models have better prediction accuracy than baselines. furthermore, we analyze the positive and false negative predictions based on a sample drug and the results point to some future directions including 1) improve medical ontology system with real world evidence,\"\n",
            " \"[ABSTRACT] transferring knowledge among various environments is important for efficiently learning multiple tasks online. most existing methods directly use the previously learned models or previously learned optimal policies to learn new tasks. however, these methods may be inefficient when the underlying models or optimal policies are substantially different across tasks. in this paper, we propose template learning (temple), a pac-mdp method for multi-task reinforcement learning that could be applied to tasks with varying state/action space without prior knowledge of inter-task mappings. temple gains sample efficiency by extracting similarities of the transition dynamics across tasks even when their underlying models or optimal policies have limited commonalities. we present two algorithms for an ``online'' and a ``finite-model'' setting respectively. we prove that our proposed temple algorithms achieve much lower sample complexity than single-task learners or state-of-the-art multi-task methods. we show via systematically designed experiments that our temple method universally outperforms the state-of-the-art multi-task methods (pac-mdp or not) in various settings and regimes. [METHOD] ['temple (template learning) for multi-task reinforcement learning'] [FUTURE_WORK] ['investigating transition probability and reward separately', 'extending the idea of extracting modular similarities to continuous mdp and deep model-based rl'] [CONCLUSION] conclusion:in this work, we propose temple, the first pac-mdp mtrl algorithm that works for tasks with varying state/action space without any inter-task mappings or prior knowledge of the mdp structures. this work can be extended in many directions. for example, one may benefit from investigating transition probability and reward separately. the idea of extracting modular similarities can also be extended to continuous mdp and deep model-based rl.\"\n",
            " \"[ABSTRACT] given the recent success of deep learning applied to a variety of single tasks, it is natural to consider more human-realistic settings. perhaps the most difficult of these settings is that of continual lifelong learning, where the model must learn online over a continuous stream of non-stationary data. a successful continual lifelong learning system must have three key capabilities: it must learn and adapt over time, it must not forget what it has learned, and it must be efficient in both training time and memory. recent techniques have focused their efforts primarily on the first two capabilities while questions of efficiency remain largely unexplored. in this paper, we consider the problem of efficient and effective storage of experiences over very large time-frames. in particular we consider the case where typical experiences are o(n) bits and memories are limited to o(k) bits for k [METHOD] ['efficient storage of experiences over very large time-frames', 'limit experiences to o(n) bits and memory to o(k) bits for scalability'] [FUTURE_WORK] ['exploring further improvements in training efficiency and memory usage', 'investigating the impact of scalability on different types of experiences']\"]\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('research_gaps_dataset.csv')\n",
        "\n",
        "print(f\"Dataset loaded: {df.shape}\")\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# Checking gap corpus\n",
        "print(\"\\nSample gap corpus:\")\n",
        "print(df['gap_corpus'].head(5).values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-LwK5GV8G7C",
        "outputId": "14a2c9fe-2547-43ab-de94-2c3525cd416b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "gap extraction stats\n",
            "gap_corpus: 80318 entries\n",
            "gap_sentences: 40105051 entries\n",
            "future_work_cleaned: 80318 entries\n",
            "contextual_gaps: 7455434 entries\n",
            "sample training data\n",
            "\n",
            "sample 1\n",
            "field: Artificial Intelligence\n",
            "title: Generalizable Representation Learning for Mixture Domain Face Anti-Spoofing\n",
            "gap corpus length: 3246 chars\n",
            "future work: ['further enhance interpretability and visualization', 'explore applications to other domains beyond\n",
            "\n",
            "sample 2\n",
            "field: Artificial Intelligence\n",
            "title: Coordinating Human and Agent Behavior in Collective-Risk Scenarios\n",
            "gap corpus length: 1532 chars\n",
            "future work: ['explore further applications of anticipatory behavior in complex social scenarios.', 'investigate \n",
            "\n",
            "sample 3\n",
            "field: Artificial Intelligence\n",
            "title: Adverse Drug Reaction Prediction with Symbolic Latent Dirichlet Allocation\n",
            "gap corpus length: 2823 chars\n",
            "future work: ['improvement of the medical ontology system with real-world evidence.', 'addressing issues related \n"
          ]
        }
      ],
      "source": [
        "gap_stats = {\n",
        "    'gap_corpus': df['gap_corpus'].notna().sum(),\n",
        "    'gap_sentences': df['gap_sentences'].str.len().sum() if 'gap_sentences' in df.columns else 0,\n",
        "    'future_work_cleaned': df['future_work_cleaned'].notna().sum(),\n",
        "    'contextual_gaps': df['contextual_gaps'].str.len().sum() if 'contextual_gaps' in df.columns else 0\n",
        "}\n",
        "\n",
        "print(\"gap extraction stats\")\n",
        "for col, count in gap_stats.items():\n",
        "    print(f\"{col}: {count} entries\")\n",
        "\n",
        "print(\"sample training data\")\n",
        "sample_papers = df[df['gap_corpus'].str.len() > 100].head(3)\n",
        "\n",
        "for i, (idx, row) in enumerate(sample_papers.iterrows()):\n",
        "    print(f\"\\nsample {i+1}\")\n",
        "    print(f\"field: {row['field']}\")\n",
        "    print(f\"title: {row['title'][:80]}\")\n",
        "    print(f\"gap corpus length: {len(row['gap_corpus'])} chars\")\n",
        "    print(f\"future work: {row['future_work_cleaned'][:100]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2W_VdOK4A3jy"
      },
      "outputs": [],
      "source": [
        "def create_transformer_training_data(df):\n",
        "    # Input: Paper sections\n",
        "    # Output: Research gaps\n",
        "\n",
        "    training_examples = []\n",
        "\n",
        "    for idx, row in df.iterrows():\n",
        "        if pd.isna(row['gap_corpus']) or len(row['gap_corpus']) < 50:\n",
        "            continue\n",
        "\n",
        "        # combining paper sections\n",
        "        input_sections = []\n",
        "\n",
        "        if pd.notna(row['title']):\n",
        "            input_sections.append(f\"Title: {row['title']}\")\n",
        "        if pd.notna(row['abstract_cleaned']):\n",
        "            input_sections.append(f\"Abstract: {row['abstract_cleaned'][:500]}\")\n",
        "        if pd.notna(row['method_proposed_cleaned']):\n",
        "            input_sections.append(f\"Method: {row['method_proposed_cleaned'][:400]}\")\n",
        "        if pd.notna(row['conclusion_cleaned']):\n",
        "            input_sections.append(f\"Conclusion: {row['conclusion_cleaned'][:300]}\")\n",
        "\n",
        "        paper_input = \"\\n\".join(input_sections)\n",
        "\n",
        "        # extracting research gaps from processed columns\n",
        "        research_gaps = []\n",
        "\n",
        "        # Future work\n",
        "        if pd.notna(row['future_work_cleaned']) and len(row['future_work_cleaned']) > 20:\n",
        "            research_gaps.append(f\"Future Research: {row['future_work_cleaned'][:200]}\")\n",
        "\n",
        "        # Gap sentences\n",
        "        if 'gap_sentences' in df.columns and pd.notna(row['gap_sentences']):\n",
        "            if isinstance(row['gap_sentences'], list) and len(row['gap_sentences']) > 0:\n",
        "                for gap in row['gap_sentences'][:3]:\n",
        "                    if len(gap) > 20:\n",
        "                        research_gaps.append(f\"Limitation: {gap[:150]}\")\n",
        "\n",
        "        if len(research_gaps) > 0 and len(paper_input) > 100:\n",
        "            gap_output = \"\\n\".join(research_gaps)\n",
        "\n",
        "            training_examples.append({\n",
        "                'input_text': paper_input,\n",
        "                'target_text': gap_output,\n",
        "                'field': row['field'],\n",
        "                'paper_id': row['paperID']\n",
        "            })\n",
        "\n",
        "    return training_examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-PjjaF1LjwV",
        "outputId": "92fc6fe9-4159-4ab4-f124-85d1548e9714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating training dataset\n",
            "Created 80080 training examples\n",
            "\n",
            "training data ny field:\n",
            "Computational Theory: 16095 examples\n",
            "Computer Vision: 14779 examples\n",
            "Natural Language Processing: 13868 examples\n",
            "Artificial Intelligence: 11890 examples\n",
            "Human Computer Interaction: 6882 examples\n",
            "Computing in Biomedical Fields: 4575 examples\n",
            "Computer Networks & Communications: 3852 examples\n",
            "Graphics and Computer-Aided Design: 3046 examples\n",
            "Software Engineering: 2333 examples\n",
            "Computer Hardware & Architecture: 1214 examples\n"
          ]
        }
      ],
      "source": [
        "# Creating training dataset\n",
        "print(\"Creating training dataset\")\n",
        "training_examples = create_transformer_training_data(df)\n",
        "print(f\"Created {len(training_examples)} training examples\")\n",
        "\n",
        "# Showing distribution by field\n",
        "field_counts = {}\n",
        "for example in training_examples:\n",
        "    field = example['field']\n",
        "    field_counts[field] = field_counts.get(field, 0) + 1\n",
        "\n",
        "print(\"\\ntraining data ny field:\")\n",
        "for field, count in sorted(field_counts.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "    print(f\"{field}: {count} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhsYXc_zHWbY",
        "outputId": "dcfd0b16-db5d-4e57-8ed9-a8483d71afe3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Custom Transformer Model Defined\n"
          ]
        }
      ],
      "source": [
        "# Custom Transformer Model\n",
        "class CustomResearchGapTransformer(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model=512, nhead=8, num_encoder_layers=6,\n",
        "                 num_decoder_layers=6, dim_feedforward=2048, max_seq_length=1024, dropout=0.1):\n",
        "        super(CustomResearchGapTransformer, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.max_seq_length = max_seq_length\n",
        "\n",
        "        # Embedding layers\n",
        "        self.input_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.output_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
        "\n",
        "        # Encoder and Decoder separately\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(\n",
        "            encoder_layer, num_layers=num_encoder_layers\n",
        "        )\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=d_model,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_decoder = nn.TransformerDecoder(\n",
        "            decoder_layer, num_layers=num_decoder_layers\n",
        "        )\n",
        "\n",
        "        # Output projection\n",
        "        self.output_projection = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "        # Research gap specific layers\n",
        "        self.gap_classifier = nn.Linear(d_model, 7)\n",
        "        self.gap_importance = nn.Linear(d_model, 1)\n",
        "\n",
        "    def create_padding_mask(self, x, pad_token_id=0):\n",
        "        return (x == pad_token_id)\n",
        "\n",
        "    def create_causal_mask(self, size):\n",
        "        mask = torch.triu(torch.ones(size, size), diagonal=1)\n",
        "        return mask.bool()\n",
        "\n",
        "    def forward(self, src, tgt, src_pad_mask=None, tgt_pad_mask=None):\n",
        "        batch_size, src_seq_len = src.shape\n",
        "        tgt_seq_len = tgt.shape[1]\n",
        "\n",
        "        # Creating padding masks\n",
        "        if src_pad_mask is None:\n",
        "            src_pad_mask = self.create_padding_mask(src)\n",
        "        if tgt_pad_mask is None:\n",
        "            tgt_pad_mask = self.create_padding_mask(tgt)\n",
        "\n",
        "        # Creating causal masks\n",
        "        tgt_causal_mask = self.create_causal_mask(tgt_seq_len).to(src.device)\n",
        "\n",
        "        # Embeddings with positional encoding\n",
        "        src_emb = self.input_embedding(src) * math.sqrt(self.d_model)\n",
        "        tgt_emb = self.output_embedding(tgt) * math.sqrt(self.d_model)\n",
        "\n",
        "        src_emb = self.positional_encoding(src_emb)\n",
        "        tgt_emb = self.positional_encoding(tgt_emb)\n",
        "\n",
        "        # Encoder forward pass\n",
        "        encoder_output = self.transformer_encoder(\n",
        "            src_emb,\n",
        "            src_key_padding_mask=src_pad_mask\n",
        "        )\n",
        "\n",
        "        # Decoder forward pass\n",
        "        decoder_output = self.transformer_decoder(\n",
        "            tgt_emb,\n",
        "            encoder_output,\n",
        "            tgt_mask=tgt_causal_mask,\n",
        "            tgt_key_padding_mask=tgt_pad_mask,\n",
        "            memory_key_padding_mask=src_pad_mask\n",
        "        )\n",
        "\n",
        "        # Output projections\n",
        "        gap_text_logits = self.output_projection(decoder_output)\n",
        "\n",
        "        # Using encoder output for global context\n",
        "        encoder_mask = ~src_pad_mask.unsqueeze(-1)  # Inverting mask for multiplication\n",
        "        masked_encoder_output = encoder_output * encoder_mask.float()\n",
        "        global_features = masked_encoder_output.sum(dim=1) / encoder_mask.sum(dim=1).float()\n",
        "\n",
        "        gap_types = self.gap_classifier(global_features)\n",
        "        gap_scores = self.gap_importance(global_features)\n",
        "\n",
        "        return {\n",
        "            'gap_text': gap_text_logits,\n",
        "            'gap_types': gap_types,\n",
        "            'gap_scores': gap_scores.squeeze(-1)\n",
        "        }\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000, droput=0.1):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() *\n",
        "                           (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.register_parameter('pe', nn.Parameter(pe.unsqueeze(0), requires_grad=False))\n",
        "\n",
        "    def forward(self, x):\n",
        "        seq_len = x.size(1)\n",
        "        return x + self.pe[:, :seq_len, :].to(x.device)\n",
        "\n",
        "print(\"Custom Transformer Model Defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Wrp2muH_NVha"
      },
      "outputs": [],
      "source": [
        "# Building vocabulary from dataset\n",
        "class ResearchGapVocabulary:\n",
        "    def __init__(self, min_freq=2):\n",
        "        self.min_freq = min_freq\n",
        "        self.word2idx = {'<PAD>': 0, '<UNK>': 1, '<SOS>': 2, '<EOS>': 3}\n",
        "        self.idx2word = {0: '<PAD>', 1: '<UNK>', 2: '<SOS>', 3: '<EOS>'}\n",
        "        self.vocab_size = 4\n",
        "\n",
        "    def build_vocabulary(self, texts):\n",
        "        print(\"Building vocabulary from research papers\")\n",
        "\n",
        "        word_counts = Counter()\n",
        "        for text in texts:\n",
        "            # Tokenization\n",
        "            words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "            word_counts.update(words)\n",
        "\n",
        "        for word, count in word_counts.items():\n",
        "            if count >= self.min_freq and word not in self.word2idx:\n",
        "                self.word2idx[word] = self.vocab_size\n",
        "                self.idx2word[self.vocab_size] = word\n",
        "                self.vocab_size += 1\n",
        "\n",
        "        print(f\"Vocabulary built: {self.vocab_size} words\")\n",
        "        return word_counts\n",
        "\n",
        "    def text_to_indices(self, text, max_length=512):\n",
        "        words = re.findall(r'\\b\\w+\\b', text.lower())\n",
        "        indices = [self.word2idx.get(word, 1) for word in words]  # 1=<UNK>\n",
        "\n",
        "        # Adding SOS token at beginning, EOS at end\n",
        "        indices = [2] + indices + [3]  # 2=<SOS>, 3=<EOS>\n",
        "\n",
        "        # Padding to max_length\n",
        "        if len(indices) > max_length:\n",
        "            indices = indices[:max_length-1] + [3]  # Keeping EOS token\n",
        "        else:\n",
        "            indices += [0] * (max_length - len(indices))  # 0=<PAD>\n",
        "\n",
        "        return indices\n",
        "\n",
        "    def indices_to_text(self, indices):\n",
        "        # Converting indices back to text\n",
        "        words = []\n",
        "        for idx in indices:\n",
        "            if idx == 3:  # EOS token\n",
        "                break\n",
        "            if idx not in [0, 1, 2]:  # Skipping PAD, UNK, SOS\n",
        "                words.append(self.idx2word.get(idx, '<UNK>'))\n",
        "        return ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTYpKXFLLrwk",
        "outputId": "a033fab1-ff10-4252-b4b9-2ca7fab7eea0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Building vocabulary from research papers\n",
            "Vocabulary built: 53657 words\n",
            "Vocabulary Statistics:\n",
            "\n",
            "Total unique words: 103209\n",
            "\n",
            "Vocabulary size: 53657\n",
            "\n",
            "Most common words: [('the', 468884), ('of', 384901), ('to', 279725), ('and', 275810), ('in', 245934), ('a', 233653), ('for', 232795), ('we', 131127), ('method', 112396), ('on', 104444)]\n"
          ]
        }
      ],
      "source": [
        "# Building vocabulary from training data\n",
        "all_texts = []\n",
        "for example in training_examples:\n",
        "    all_texts.append(example['input_text'])\n",
        "    all_texts.append(example['target_text'])\n",
        "\n",
        "vocabulary = ResearchGapVocabulary(min_freq=3)\n",
        "word_counts = vocabulary.build_vocabulary(all_texts)\n",
        "\n",
        "print(f\"Vocabulary Statistics:\")\n",
        "print(f\"\\nTotal unique words: {len(word_counts)}\")\n",
        "print(f\"\\nVocabulary size: {vocabulary.vocab_size}\")\n",
        "print(f\"\\nMost common words: {word_counts.most_common(10)}\")\n",
        "\n",
        "with open('research_gap_vocabulary.pkl', 'wb') as f:\n",
        "    pickle.dump(vocabulary, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "sKE_iPr4PN8K"
      },
      "outputs": [],
      "source": [
        "# Custom dataset class\n",
        "class ResearchGapDataset(Dataset):\n",
        "    def __init__(self, training_examples, vocabulary, max_input_length=512, max_output_length=256):\n",
        "        self.examples = training_examples\n",
        "        self.vocabulary = vocabulary\n",
        "        self.max_input_length = max_input_length\n",
        "        self.max_output_length = max_output_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.examples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        example = self.examples[idx]\n",
        "\n",
        "        # Converting texts to indices\n",
        "        input_indices = self.vocabulary.text_to_indices(\n",
        "            example['input_text'], self.max_input_length\n",
        "        )\n",
        "        target_indices = self.vocabulary.text_to_indices(\n",
        "            example['target_text'], self.max_output_length\n",
        "        )\n",
        "\n",
        "        # Creating decoder input\n",
        "        decoder_input = target_indices[:-1]  # Removing last token\n",
        "        decoder_target = target_indices[1:]   # Removing first token\n",
        "\n",
        "        # Padding decoder sequences to same length\n",
        "        if len(decoder_input) < self.max_output_length - 1:\n",
        "            pad_length = self.max_output_length - 1 - len(decoder_input)\n",
        "            decoder_input.extend([0] * pad_length)\n",
        "            decoder_target.extend([0] * pad_length)\n",
        "\n",
        "        return {\n",
        "            'input_ids': torch.tensor(input_indices, dtype=torch.long),\n",
        "            'decoder_input': torch.tensor(decoder_input, dtype=torch.long),\n",
        "            'decoder_target': torch.tensor(decoder_target, dtype=torch.long),\n",
        "            'field': example['field'],\n",
        "            'paper_id': example['paper_id']\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_sKLgZJLxk0",
        "outputId": "470aca3b-fdbf-4621-dd9f-50643fa2a208"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset Splits:\n",
            "\n",
            "Training: 64064 examples\n",
            "\n",
            "Validation: 8008 examples\n",
            "\n",
            "Test: 8008 examples\n",
            "Data loaders created with batch size: 8\n",
            "\n",
            "Data loaders created with batch size: 8 and dynamic padding.\n"
          ]
        }
      ],
      "source": [
        "# Creating dataset splits\n",
        "train_size = int(0.8 * len(training_examples))\n",
        "val_size = int(0.1 * len(training_examples))\n",
        "test_size = len(training_examples) - train_size - val_size\n",
        "\n",
        "train_examples = training_examples[:train_size]\n",
        "val_examples = training_examples[train_size:train_size + val_size]\n",
        "test_examples = training_examples[train_size + val_size:]\n",
        "\n",
        "print(f\"\\nDataset Splits:\")\n",
        "print(f\"\\nTraining: {len(train_examples)} examples\")\n",
        "print(f\"\\nValidation: {len(val_examples)} examples\")\n",
        "print(f\"\\nTest: {len(test_examples)} examples\")\n",
        "\n",
        "# Creating datasets\n",
        "train_dataset = ResearchGapDataset(train_examples, vocabulary)\n",
        "val_dataset = ResearchGapDataset(val_examples, vocabulary)\n",
        "test_dataset = ResearchGapDataset(test_examples, vocabulary)\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "print(f\"Data loaders created with batch size: {BATCH_SIZE}\")\n",
        "def collate_fn(batch):\n",
        "    input_ids = torch.nn.utils.rnn.pad_sequence(\n",
        "        [item['input_ids'] for item in batch], batch_first=True, padding_value=vocabulary.word2idx['<PAD>']\n",
        "    )\n",
        "    decoder_inputs = torch.nn.utils.rnn.pad_sequence(\n",
        "        [item['decoder_input'] for item in batch], batch_first=True, padding_value=vocabulary.word2idx['<PAD>']\n",
        "    )\n",
        "    decoder_targets = torch.nn.utils.rnn.pad_sequence(\n",
        "        [item['decoder_target'] for item in batch], batch_first=True, padding_value=vocabulary.word2idx['<PAD>']\n",
        "    )\n",
        "\n",
        "    fields = [item['field'] for item in batch]\n",
        "    paper_ids = [item['paper_id'] for item in batch]\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_ids,\n",
        "        'decoder_input': decoder_inputs,\n",
        "        'decoder_target': decoder_targets,\n",
        "        'field': fields,\n",
        "        'paper_id': paper_ids\n",
        "    }\n",
        "\n",
        "# Creating data loaders with the collate_fn\n",
        "BATCH_SIZE = 8\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "print(f\"\\nData loaders created with batch size: {BATCH_SIZE} and dynamic padding.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kACxcMrnPTJ6",
        "outputId": "561b4823-1426-44c6-b896-e36eca42c7a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Configuration:\n",
            "   vocab_size: 53657\n",
            "   d_model: 256\n",
            "   nhead: 8\n",
            "   num_encoder_layers: 4\n",
            "   num_decoder_layers: 4\n",
            "   dim_feedforward: 1024\n",
            "   dropout: 0.3\n",
            "Using device: cuda\n",
            "\n",
            "New model initialized and pre-trained weights loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "# Model hyperparameters\n",
        "MODEL_CONFIG = {\n",
        "    'vocab_size': vocabulary.vocab_size,\n",
        "    'd_model': 256,\n",
        "    'nhead': 8,\n",
        "    'num_encoder_layers': 4,\n",
        "    'num_decoder_layers': 4,\n",
        "    'dim_feedforward': 1024,\n",
        "    'dropout': 0.3\n",
        "}\n",
        "\n",
        "print(f\"Model Configuration:\")\n",
        "for key, value in MODEL_CONFIG.items():\n",
        "    print(f\"   {key}: {value}\")\n",
        "\n",
        "# Initializing fixed model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if 'model' in locals():\n",
        "    del model\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model = CustomResearchGapTransformer(**MODEL_CONFIG)\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"\\nNew model initialized and pre-trained weights loaded successfully.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwX5haB3Pa21",
        "outputId": "3b29d531-4061-45d2-9f49-9be1976a0301"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fixed Model Statistics:\n",
            "\n",
            "Total parameters: 48,899,233\n",
            "\n",
            "Trainable parameters: 48,637,089\n",
            "\n",
            "Model size: ~186.5 MB\n",
            "\n",
            "Testing fixed model with sample batch...\n",
            "\n",
            "Input shape: torch.Size([8, 512])\n",
            "\n",
            "Decoder input shape: torch.Size([8, 255])\n",
            "Fixed model forward pass successful!\n",
            "\n",
            "Gap text output shape: torch.Size([8, 255, 53657])\n",
            "\n",
            "Gap types output shape: torch.Size([8, 7])\n",
            "\n",
            "Gap scores output shape: torch.Size([8])\n",
            "\n",
            "Sample Output Statistics:\n",
            "\n",
            "Gap text logits range: [-3.200, 3.061]\n",
            "\n",
            "Gap types range: [-0.409, 0.411]\n",
            "\n",
            "Gap scores range: [-0.112, 0.359]\n"
          ]
        }
      ],
      "source": [
        "# Counting parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\nFixed Model Statistics:\")\n",
        "print(f\"\\nTotal parameters: {total_params:,}\")\n",
        "print(f\"\\nTrainable parameters: {trainable_params:,}\")\n",
        "print(f\"\\nModel size: ~{total_params * 4 / (1024**2):.1f} MB\")\n",
        "\n",
        "# Testing model with sample batch\n",
        "sample_batch = next(iter(train_loader))\n",
        "print(f\"\\nTesting fixed model with sample batch...\")\n",
        "print(f\"\\nInput shape: {sample_batch['input_ids'].shape}\")\n",
        "print(f\"\\nDecoder input shape: {sample_batch['decoder_input'].shape}\")\n",
        "\n",
        "# Moving to device and testing forward pass\n",
        "sample_input = sample_batch['input_ids'].to(device)\n",
        "sample_decoder = sample_batch['decoder_input'].to(device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    try:\n",
        "        output = model(sample_input, sample_decoder)\n",
        "        print(f\"Fixed model forward pass successful!\")\n",
        "        print(f\"\\nGap text output shape: {output['gap_text'].shape}\")\n",
        "        print(f\"\\nGap types output shape: {output['gap_types'].shape}\")\n",
        "        print(f\"\\nGap scores output shape: {output['gap_scores'].shape}\")\n",
        "\n",
        "        # Testing actual values\n",
        "        print(f\"\\nSample Output Statistics:\")\n",
        "        print(f\"\\nGap text logits range: [{output['gap_text'].min():.3f}, {output['gap_text'].max():.3f}]\")\n",
        "        print(f\"\\nGap types range: [{output['gap_types'].min():.3f}, {output['gap_types'].max():.3f}]\")\n",
        "        print(f\"\\nGap scores range: [{output['gap_scores'].min():.3f}, {output['gap_scores'].max():.3f}]\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Model forward pass still failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmmF6YWjgjTW",
        "outputId": "1e304589-0037-43c8-8460-60754f42b1af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Configuration:\n",
            "  num_epochs: 15\n",
            "  learning_rate: 5e-05\n",
            "  batch_size: 16\n",
            "  weight_decay: 0.01\n",
            "  gradient_clipping: 0.5\n",
            "  early_stopping_patience: 3\n",
            "  reduce_lr_patience: 2\n",
            "  reduce_lr_factor: 0.5\n",
            "\n",
            "New training configuration, loss function, optimizer, and scheduler are ready.\n"
          ]
        }
      ],
      "source": [
        "# Defining Training Hyperparameters\n",
        "TRAINING_CONFIG = {\n",
        "    'num_epochs': 15,\n",
        "    'learning_rate': 5e-5,\n",
        "    'batch_size': 16,\n",
        "    'weight_decay': 0.01, # L2 regularization\n",
        "    'gradient_clipping': 0.5,\n",
        "    'early_stopping_patience': 3,\n",
        "    'reduce_lr_patience': 2,\n",
        "    'reduce_lr_factor': 0.5\n",
        "}\n",
        "\n",
        "print(\"Training Configuration:\")\n",
        "for key, value in TRAINING_CONFIG.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Defining the Combined Loss Function Dictionary\n",
        "criterion = {\n",
        "    'gap_text': CrossEntropyLoss(ignore_index=vocabulary.word2idx['<PAD>']),\n",
        "    'gap_type': CrossEntropyLoss(),\n",
        "    'gap_score': MSELoss()\n",
        "}\n",
        "\n",
        "# Creating the Optimizer and Scheduler for the training run\n",
        "optimizer = optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=TRAINING_CONFIG['learning_rate'],\n",
        "    weight_decay=TRAINING_CONFIG['weight_decay']\n",
        ")\n",
        "\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer,\n",
        "    mode='min',\n",
        "    patience=TRAINING_CONFIG['reduce_lr_patience'],\n",
        "    factor=TRAINING_CONFIG['reduce_lr_factor']\n",
        "    )\n",
        "\n",
        "print(\"\\nNew training configuration, loss function, optimizer, and scheduler are ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "Nuyen-yNQ0A5"
      },
      "outputs": [],
      "source": [
        "class ResearchGapTrainer:\n",
        "    def __init__(self, model, criterion, optimizer, scheduler, device):\n",
        "        self.model = model\n",
        "        self.criterion = criterion\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "\n",
        "        # training history\n",
        "        self.train_losses = []\n",
        "        self.val_losses = []\n",
        "        self.learning_rates = []\n",
        "\n",
        "    def train_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        num_batches = len(train_loader)\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=\"training\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(progress_bar):\n",
        "            # moving batch to device\n",
        "            input_ids = batch['input_ids'].to(self.device)\n",
        "            decoder_input = batch['decoder_input'].to(self.device)\n",
        "            decoder_target = batch['decoder_target'].to(self.device)\n",
        "\n",
        "            # forward pass\n",
        "            self.optimizer.zero_grad()\n",
        "            predictions = self.model(input_ids, decoder_input)\n",
        "\n",
        "            # loss calculation\n",
        "            loss_text = self.criterion['gap_text'](predictions['gap_text'].reshape(-1, predictions['gap_text'].size(-1)), decoder_target.reshape(-1))\n",
        "            loss = loss_text\n",
        "\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # gradient limiting\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "\n",
        "            # weight update\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            progress_bar.set_postfix({'loss': f'{total_loss / (batch_idx + 1):.4f}'})\n",
        "\n",
        "        return {'total_loss': total_loss / len(train_loader)}\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        # validating the model\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_text_loss = 0\n",
        "        num_batches = len(val_loader)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=\"validation\"):\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                decoder_input = batch['decoder_input'].to(self.device)\n",
        "                decoder_target = batch['decoder_target'].to(self.device)\n",
        "\n",
        "                predictions = self.model(input_ids, decoder_input)\n",
        "                loss = self.criterion['gap_text'](predictions['gap_text'].reshape(-1, predictions['gap_text'].size(-1)), decoder_target.reshape(-1))\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        return {'total_loss': total_loss / len(val_loader)}\n",
        "\n",
        "\n",
        "    def train(self, train_loader, val_loader, num_epochs):\n",
        "        # completing training loop\n",
        "        print(f\"starting training for {num_epochs} epochs...\")\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        patience_counter = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nepoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "            # training\n",
        "            start_time = time.time()\n",
        "            train_metrics = self.train_epoch(train_loader)\n",
        "            train_time = time.time() - start_time\n",
        "\n",
        "            # validation\n",
        "            start_time = time.time()\n",
        "            val_metrics = self.validate(val_loader)\n",
        "            val_time = time.time() - start_time\n",
        "\n",
        "            # updating learning rate\n",
        "            self.scheduler.step(val_metrics['total_loss'])\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # stori history\n",
        "            self.train_losses.append(train_metrics['total_loss'])\n",
        "            self.val_losses.append(val_metrics['total_loss'])\n",
        "            self.learning_rates.append(current_lr)\n",
        "\n",
        "            # epoch summary\n",
        "            print(f\"\\nepoch {epoch + 1} results:\")\n",
        "            print(f\"\\ntrain loss: {train_metrics['total_loss']:.4f} ({train_time:.1f}s)\")\n",
        "            print(f\"\\nval loss: {val_metrics['total_loss']:.4f} ({val_time:.1f}s)\")\n",
        "            print(f\"\\nlearning rate: {current_lr:.2e}\")\n",
        "            print(f\"\\ntext loss: {train_metrics['text_loss']:.4f}\")\n",
        "\n",
        "            # saved best model\n",
        "            if val_metrics['total_loss'] < best_val_loss:\n",
        "                best_val_loss = val_metrics['total_loss']\n",
        "                self.save_model('best_research_gap_model.pt', epoch, val_metrics['total_loss'])\n",
        "                patience_counter = 0\n",
        "                print(f\"\\nnew best model saved!\")\n",
        "            else:\n",
        "                patience_counter += 1\n",
        "\n",
        "            # early stopping\n",
        "            if patience_counter >= 5:\n",
        "                print(f\"\\nearly stopping triggered (patience: 5)\")\n",
        "                break\n",
        "\n",
        "            # saved checkpoint every few epochs\n",
        "            if (epoch + 1) % 3 == 0:\n",
        "                self.save_model(f'checkpoint_epoch_{epoch+1}.pt', epoch, val_metrics['total_loss'])\n",
        "\n",
        "        print(f\"\\ntraining completed!\")\n",
        "        print(f\"\\nbest validation loss: {best_val_loss:.4f}\")\n",
        "\n",
        "    def save_model(self, filename, epoch, val_loss):\n",
        "        # saved model checkpoint\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': self.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'val_loss': val_loss,\n",
        "            'vocab_size': self.model.output_projection.in_features,\n",
        "            'model_config': MODEL_CONFIG\n",
        "        }, filename)\n",
        "\n",
        "    def plot_training_history(self):\n",
        "      # plotting training curves\n",
        "      fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
        "\n",
        "      ax.plot(self.train_losses, label='training loss', color='blue')\n",
        "      ax.plot(self.val_losses, label='validation loss', color='red')\n",
        "      ax.set_xlabel('epoch')\n",
        "      ax.set_ylabel('loss')\n",
        "      ax.set_title('training and validation loss')\n",
        "      ax.set_ylim(2.75, 4.75)\n",
        "      ax.legend()\n",
        "      ax.grid(True)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.savefig('training_history_loss.png', dpi=300, bbox_inches='tight')\n",
        "      plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "WhPmmgWLREah"
      },
      "outputs": [],
      "source": [
        "class ResumeableTrainer(ResearchGapTrainer):\n",
        "    def __init__(self, model, criterion, optimizer, scheduler, device, checkpoint_dir='checkpoints'):\n",
        "        super().__init__(model, criterion, optimizer, scheduler, device)\n",
        "        self.checkpoint_dir = checkpoint_dir\n",
        "        os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    def cleanup_drive_backups(self, keep_last=5):\n",
        "        try:\n",
        "            drive.mount('/content/drive', force_remount=True)\n",
        "            backup_pattern = '/content/drive/MyDrive/research_gap_backup_epoch_*_batch_*.pt'\n",
        "            backups = glob.glob(backup_pattern)\n",
        "\n",
        "            if len(backups) <= keep_last:\n",
        "                print(f\"only {len(backups)} drive backups found. no cleanup needed.\")\n",
        "                return\n",
        "\n",
        "            backup_info = []\n",
        "            for backup in backups:\n",
        "                match = re.search(r'backup_epoch_(\\d+)_batch_(\\d+)\\.pt', backup)\n",
        "                if match:\n",
        "                    epoch, batch = int(match.group(1)), int(match.group(2))\n",
        "                    backup_info.append((epoch, batch, backup))\n",
        "\n",
        "            backup_info.sort(key=lambda x: (x[0], x[1]))\n",
        "            backups_to_delete = backup_info[:-keep_last]\n",
        "\n",
        "            deleted_count = 0\n",
        "            for epoch, batch, backup_path in backups_to_delete:\n",
        "                try:\n",
        "                    os.remove(backup_path)\n",
        "                    print(f\"deleted old drive backup: epoch_{epoch}_batch_{batch}\")\n",
        "                    deleted_count += 1\n",
        "                except Exception as e:\n",
        "                    print(f\"failed to delete {backup_path}: {e}\")\n",
        "\n",
        "            print(f\"cleaned up {deleted_count} old drive backups. kept {keep_last} most recent.\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"drive backup cleanup failed: {e}\")\n",
        "\n",
        "    def save_epoch_model_to_drive(self, epoch, train_loss, val_loss):\n",
        "        try:\n",
        "            drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "            epoch_model_path = f'/content/drive/MyDrive/research_gap_epoch_{epoch}_model.pt'\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'train_loss': train_loss,\n",
        "                'val_loss': val_loss,\n",
        "                'model_config': MODEL_CONFIG,\n",
        "                'vocabulary': vocabulary\n",
        "            }, epoch_model_path)\n",
        "\n",
        "            print(f\"epoch {epoch} trained model saved to drive: {epoch_model_path}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"failed to save epoch model to drive: {e}\")\n",
        "\n",
        "    def save_checkpoint(self, epoch, batch_idx, loss):\n",
        "        try:\n",
        "            drive_path = f'/content/drive/MyDrive/research_gap_backup_epoch_{epoch}_batch_{batch_idx}.pt'\n",
        "\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'batch_idx': batch_idx,\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "                'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "                'loss': loss,\n",
        "                'vocab_size': self.model.output_projection.in_features,\n",
        "                'model_config': MODEL_CONFIG,\n",
        "                'train_losses': self.train_losses,\n",
        "                'val_losses': self.val_losses\n",
        "            }, drive_path)\n",
        "\n",
        "            print(f\"checkpoint saved to google drive: {drive_path}\")\n",
        "\n",
        "            self.cleanup_drive_backups(keep_last=3)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"failed to save checkpoint to drive: {e}\")\n",
        "\n",
        "    def find_latest_checkpoint(self):\n",
        "        checkpoint_pattern = f\"{self.checkpoint_dir}/checkpoint_epoch_*_batch_*.pt\"\n",
        "        checkpoints = glob.glob(checkpoint_pattern)\n",
        "\n",
        "        if not checkpoints:\n",
        "            print(\"no local checkpoints found. checking google drive...\")\n",
        "            return self.find_latest_checkpoint_from_drive()\n",
        "\n",
        "        latest_checkpoint = None\n",
        "        latest_epoch = -1\n",
        "        latest_batch = -1\n",
        "\n",
        "        for cp in checkpoints:\n",
        "            match = re.search(r'checkpoint_epoch_(\\d+)_batch_(\\d+)\\.pt', cp)\n",
        "            if match:\n",
        "                epoch, batch = int(match.group(1)), int(match.group(2))\n",
        "                if epoch > latest_epoch or (epoch == latest_epoch and batch > latest_batch):\n",
        "                    latest_epoch, latest_batch = epoch, batch\n",
        "                    latest_checkpoint = cp\n",
        "\n",
        "        print(f\"found latest checkpoint: {latest_checkpoint}\")\n",
        "        return latest_checkpoint, latest_epoch, latest_batch\n",
        "\n",
        "    def find_latest_checkpoint_from_drive(self):\n",
        "        try:\n",
        "            drive.mount('/content/drive', force_remount=True)\n",
        "            backup_pattern = '/content/drive/MyDrive/research_gap_backup_epoch_*_batch_*.pt'\n",
        "            backups = glob.glob(backup_pattern)\n",
        "\n",
        "            if not backups:\n",
        "                print(\"no google drive backups found.\")\n",
        "                return None, 0, 0\n",
        "\n",
        "            latest_backup = None\n",
        "            latest_epoch = -1\n",
        "            latest_batch = -1\n",
        "\n",
        "            for backup in backups:\n",
        "                match = re.search(r'backup_epoch_(\\d+)_batch_(\\d+)\\.pt', backup)\n",
        "                if match:\n",
        "                    epoch, batch = int(match.group(1)), int(match.group(2))\n",
        "                    if epoch > latest_epoch or (epoch == latest_epoch and batch > latest_batch):\n",
        "                        latest_epoch, latest_batch = epoch, batch\n",
        "                        latest_backup = backup\n",
        "\n",
        "            if latest_backup:\n",
        "                local_checkpoint = f\"{self.checkpoint_dir}/checkpoint_epoch_{latest_epoch}_batch_{latest_batch}.pt\"\n",
        "                shutil.copy(latest_backup, local_checkpoint)\n",
        "                print(f\"restored checkpoint from google drive: epoch {latest_epoch}, batch {latest_batch}\")\n",
        "                return local_checkpoint, latest_epoch, latest_batch\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"failed to restore from google drive: {e}\")\n",
        "            return None, 0, 0\n",
        "\n",
        "    def load_checkpoint(self, checkpoint_path):\n",
        "        checkpoint = torch.load(checkpoint_path)\n",
        "        self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        self.train_losses = checkpoint.get('train_losses', [])\n",
        "        self.val_losses = checkpoint.get('val_losses', [])\n",
        "        return checkpoint['epoch'], checkpoint['batch_idx']\n",
        "\n",
        "    def train_epoch_with_resume(self, train_loader, epoch, skip_batches=0):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        processed_batches = 0\n",
        "\n",
        "        progress_bar = tqdm(train_loader, desc=f\"epoch {epoch+1}\")\n",
        "\n",
        "        for batch_idx, batch in enumerate(progress_bar):\n",
        "            if batch_idx < skip_batches:\n",
        "                continue\n",
        "\n",
        "            input_ids = batch['input_ids'].to(self.device)\n",
        "            decoder_input = batch['decoder_input'].to(self.device)\n",
        "            decoder_target = batch['decoder_target'].to(self.device)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            predictions = self.model(input_ids, decoder_input)\n",
        "\n",
        "            loss = self.criterion['gap_text'](\n",
        "                predictions['gap_text'].reshape(-1, predictions['gap_text'].size(-1)),\n",
        "                decoder_target.reshape(-1)\n",
        "            )\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            processed_batches += 1\n",
        "\n",
        "            progress_bar.set_postfix({'loss': f'{total_loss/processed_batches:.4f}'})\n",
        "\n",
        "            if batch_idx > 0 and batch_idx % 500 == 0:\n",
        "                avg_loss = total_loss / processed_batches\n",
        "                self.save_checkpoint(epoch, batch_idx, avg_loss)\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        return total_loss / processed_batches if processed_batches > 0 else 0\n",
        "\n",
        "    def validate(self, val_loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(val_loader, desc=\"validation\"):\n",
        "                input_ids = batch['input_ids'].to(self.device)\n",
        "                decoder_input = batch['decoder_input'].to(self.device)\n",
        "                decoder_target = batch['decoder_target'].to(self.device)\n",
        "\n",
        "                predictions = self.model(input_ids, decoder_input)\n",
        "\n",
        "                loss = self.criterion['gap_text'](\n",
        "                    predictions['gap_text'].reshape(-1, predictions['gap_text'].size(-1)),\n",
        "                    decoder_target.reshape(-1)\n",
        "                )\n",
        "                total_loss += loss.item()\n",
        "\n",
        "        return {'total_loss': total_loss / len(val_loader)}\n",
        "\n",
        "    def run_complete_training(self, train_loader, val_loader, num_epochs):\n",
        "        print(\"research gap model training\")\n",
        "\n",
        "        checkpoint_path, start_epoch, start_batch = self.find_latest_checkpoint()\n",
        "\n",
        "        if checkpoint_path:\n",
        "            print(f\"resuming from epoch {start_epoch}, batch {start_batch}\")\n",
        "            try:\n",
        "                loaded_epoch, loaded_batch = self.load_checkpoint(checkpoint_path)\n",
        "                start_epoch = loaded_epoch\n",
        "                start_batch = loaded_batch\n",
        "                print(f\"successfully loaded checkpoint from epoch {start_epoch}\")\n",
        "            except Exception as e:\n",
        "                print(f\"failed to load checkpoint: {e}\")\n",
        "                start_epoch = 0\n",
        "                start_batch = 0\n",
        "        else:\n",
        "            start_epoch = 0\n",
        "            start_batch = 0\n",
        "\n",
        "        for epoch in range(start_epoch, num_epochs):\n",
        "            print(f\"\\nstarting epoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "            skip_batches = start_batch if epoch == start_epoch else 0\n",
        "            train_loss = self.train_epoch_with_resume(train_loader, epoch, skip_batches)\n",
        "            val_metrics = self.validate(val_loader)\n",
        "            val_loss = val_metrics['total_loss']\n",
        "\n",
        "            self.scheduler.step(val_loss)\n",
        "            self.train_losses.append(train_loss)\n",
        "            self.val_losses.append(val_loss)\n",
        "\n",
        "            print(f\"epoch {epoch+1} completed:\")\n",
        "            print(f\"  train loss: {train_loss:.4f}\")\n",
        "            print(f\"  val loss: {val_loss:.4f}\")\n",
        "            print(f\"  learning rate: {self.optimizer.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "            self.save_checkpoint(epoch, len(train_loader), train_loss)\n",
        "            self.save_epoch_model_to_drive(epoch, train_loss, val_loss)\n",
        "\n",
        "            start_batch = 0\n",
        "\n",
        "        print(\"training completed!\")\n",
        "\n",
        "        try:\n",
        "            drive.mount('/content/drive', force_remount=True)\n",
        "            final_model_path = '/content/drive/MyDrive/research_gap_final_trained_model.pt'\n",
        "            torch.save({\n",
        "                'model_state_dict': self.model.state_dict(),\n",
        "                'vocabulary': vocabulary,\n",
        "                'model_config': MODEL_CONFIG,\n",
        "                'training_complete': True,\n",
        "                'final_train_loss': self.train_losses[-1] if self.train_losses else None,\n",
        "                'final_val_loss': self.val_losses[-1] if self.val_losses else None\n",
        "            }, final_model_path)\n",
        "            print(f\"final trained model saved to drive: {final_model_path}\")\n",
        "        except Exception as e:\n",
        "            print(f\"failed to save final model to drive: {e}\")\n",
        "\n",
        "        try:\n",
        "            self.plot_training_history()\n",
        "        except:\n",
        "            print(\"could not plot training history\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7bVOre_cksTm",
        "outputId": "524961a7-e47b-4695-e649-5e9ceed31d66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResumeableTrainer initialized and ready for the improved training run.\n",
            "\n",
            "STARTING IMPROVED TRAINING RUN\n",
            "research gap model training\n",
            "no local checkpoints found. checking google drive...\n",
            "Mounted at /content/drive\n",
            "restored checkpoint from google drive: epoch 12, batch 2000\n",
            "resuming from epoch 12, batch 2000\n",
            "successfully loaded checkpoint from epoch 12\n",
            "\n",
            "starting epoch 13/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  25%|██▍       | 1981/8008 [00:05<00:17, 335.40it/s, loss=3.2604]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_2000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  25%|██▍       | 2001/8008 [00:21<16:26,  6.09it/s, loss=3.2604] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "only 1 drive backups found. no cleanup needed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  31%|███       | 2500/8008 [01:54<16:48,  5.46it/s, loss=2.8401]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_2500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  31%|███       | 2501/8008 [02:08<6:58:00,  4.55s/it, loss=2.8401]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "only 2 drive backups found. no cleanup needed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  37%|███▋      | 3000/8008 [03:40<15:12,  5.49it/s, loss=2.8608]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_3000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  37%|███▋      | 3001/8008 [03:50<4:16:43,  3.08s/it, loss=2.8608]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "only 3 drive backups found. no cleanup needed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  44%|████▎     | 3500/8008 [05:21<13:41,  5.49it/s, loss=2.8740]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_3500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  44%|████▎     | 3501/8008 [05:31<3:37:53,  2.90s/it, loss=2.8740]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_2000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  50%|████▉     | 4000/8008 [07:02<12:17,  5.43it/s, loss=2.8759]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_4000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  50%|████▉     | 4001/8008 [07:19<5:46:59,  5.20s/it, loss=2.8759]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_2500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  56%|█████▌    | 4500/8008 [08:51<10:44,  5.44it/s, loss=2.8818]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_4500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  56%|█████▌    | 4501/8008 [09:02<3:19:57,  3.42s/it, loss=2.8818]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_3000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  62%|██████▏   | 5000/8008 [10:35<09:09,  5.47it/s, loss=2.8835]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_5000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  62%|██████▏   | 5001/8008 [10:45<2:49:51,  3.39s/it, loss=2.8835]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_3500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  69%|██████▊   | 5500/8008 [12:18<07:37,  5.48it/s, loss=2.8815]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_5500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  69%|██████▊   | 5501/8008 [12:27<2:05:11,  3.00s/it, loss=2.8815]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_4000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  75%|███████▍  | 6000/8008 [13:59<06:11,  5.40it/s, loss=2.8816]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_6000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  75%|███████▍  | 6001/8008 [14:15<2:48:30,  5.04s/it, loss=2.8816]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_4500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  81%|████████  | 6500/8008 [15:47<04:46,  5.27it/s, loss=2.8824]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_6500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  81%|████████  | 6501/8008 [15:58<1:27:22,  3.48s/it, loss=2.8824]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_5000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  87%|████████▋ | 7000/8008 [17:31<03:06,  5.40it/s, loss=2.8833]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_7000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  87%|████████▋ | 7001/8008 [17:45<1:13:50,  4.40s/it, loss=2.8833]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_5500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13:  94%|█████████▎| 7500/8008 [19:18<01:32,  5.48it/s, loss=2.8855]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_7500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13:  94%|█████████▎| 7501/8008 [19:30<31:37,  3.74s/it, loss=2.8855]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_6000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13: 100%|█████████▉| 8000/8008 [21:02<00:01,  5.49it/s, loss=2.8827]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_8000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 13: 100%|█████████▉| 8001/8008 [21:10<00:19,  2.77s/it, loss=2.8827]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_6500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 13: 100%|██████████| 8008/8008 [21:12<00:00,  6.30it/s, loss=2.8828]\n",
            "validation: 100%|██████████| 1001/1001 [00:44<00:00, 22.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 13 completed:\n",
            "  train loss: 2.8828\n",
            "  val loss: 2.9302\n",
            "  learning rate: 5.00e-05\n",
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_12_batch_8008.pt\n",
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_7000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n",
            "Mounted at /content/drive\n",
            "epoch 12 trained model saved to drive: /content/drive/MyDrive/research_gap_epoch_12_model.pt\n",
            "\n",
            "starting epoch 14/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:   6%|▌         | 500/8008 [01:33<22:50,  5.48it/s, loss=2.8398]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:   6%|▋         | 501/8008 [01:52<12:22:34,  5.94s/it, loss=2.8398]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_7500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  12%|█▏        | 1000/8008 [03:25<21:17,  5.48it/s, loss=2.8423]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_1000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  12%|█▎        | 1001/8008 [03:33<5:10:14,  2.66s/it, loss=2.8423]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_8000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  19%|█▊        | 1500/8008 [05:05<19:53,  5.45it/s, loss=2.8470]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_1500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  19%|█▊        | 1501/8008 [05:17<6:36:18,  3.65s/it, loss=2.8470]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_12_batch_8008\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  25%|██▍       | 2000/8008 [06:49<18:16,  5.48it/s, loss=2.8433]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_2000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  25%|██▍       | 2001/8008 [07:04<7:35:12,  4.55s/it, loss=2.8433]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  31%|███       | 2500/8008 [08:36<16:43,  5.49it/s, loss=2.8422]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_2500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  31%|███       | 2501/8008 [08:46<4:53:05,  3.19s/it, loss=2.8422]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_1000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  37%|███▋      | 3000/8008 [10:19<15:14,  5.48it/s, loss=2.8424]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_3000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  37%|███▋      | 3001/8008 [10:26<3:07:27,  2.25s/it, loss=2.8424]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_1500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  44%|████▎     | 3500/8008 [11:58<13:42,  5.48it/s, loss=2.8477]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_3500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  44%|████▎     | 3501/8008 [12:09<4:23:49,  3.51s/it, loss=2.8477]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_2000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  50%|████▉     | 4000/8008 [13:41<12:29,  5.35it/s, loss=2.8483]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_4000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  50%|████▉     | 4001/8008 [13:50<3:15:17,  2.92s/it, loss=2.8483]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_2500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  56%|█████▌    | 4500/8008 [15:22<10:39,  5.49it/s, loss=2.8501]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_4500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  56%|█████▌    | 4501/8008 [15:35<3:45:07,  3.85s/it, loss=2.8501]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_3000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  62%|██████▏   | 5000/8008 [17:07<09:08,  5.48it/s, loss=2.8514]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_5000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  62%|██████▏   | 5001/8008 [17:14<2:08:14,  2.56s/it, loss=2.8514]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_3500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  69%|██████▊   | 5500/8008 [18:47<07:41,  5.44it/s, loss=2.8518]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_5500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  69%|██████▊   | 5501/8008 [19:03<3:22:57,  4.86s/it, loss=2.8518]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_4000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  75%|███████▍  | 6000/8008 [20:35<06:06,  5.48it/s, loss=2.8530]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_6000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  75%|███████▍  | 6001/8008 [20:43<1:21:09,  2.43s/it, loss=2.8530]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_4500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  81%|████████  | 6500/8008 [22:15<04:35,  5.48it/s, loss=2.8563]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_6500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  81%|████████  | 6501/8008 [22:24<1:16:58,  3.06s/it, loss=2.8563]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_5000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  87%|████████▋ | 7000/8008 [23:56<03:04,  5.47it/s, loss=2.8597]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_7000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  87%|████████▋ | 7001/8008 [24:14<1:32:28,  5.51s/it, loss=2.8597]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_5500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14:  94%|█████████▎| 7500/8008 [25:46<01:33,  5.46it/s, loss=2.8603]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_7500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14:  94%|█████████▎| 7501/8008 [25:57<29:22,  3.48s/it, loss=2.8603]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_6000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14: 100%|█████████▉| 8000/8008 [27:29<00:01,  5.48it/s, loss=2.8614]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_8000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 14: 100%|█████████▉| 8001/8008 [27:45<00:34,  4.93s/it, loss=2.8614]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_6500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 14: 100%|██████████| 8008/8008 [27:46<00:00,  4.80it/s, loss=2.8617]\n",
            "validation: 100%|██████████| 1001/1001 [00:43<00:00, 22.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 14 completed:\n",
            "  train loss: 2.8617\n",
            "  val loss: 2.9134\n",
            "  learning rate: 5.00e-05\n",
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_13_batch_8008.pt\n",
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_13_batch_7000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n",
            "Mounted at /content/drive\n",
            "epoch 13 trained model saved to drive: /content/drive/MyDrive/research_gap_epoch_13_model.pt\n",
            "\n",
            "starting epoch 15/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:   6%|▌         | 500/8008 [01:32<22:50,  5.48it/s, loss=2.7688]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:   6%|▋         | 501/8008 [01:40<5:26:39,  2.61s/it, loss=2.7688]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "only 2 drive backups found. no cleanup needed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  12%|█▏        | 1000/8008 [03:12<21:17,  5.48it/s, loss=2.7911]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_1000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  12%|█▎        | 1001/8008 [03:28<9:46:07,  5.02s/it, loss=2.7911]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "only 2 drive backups found. no cleanup needed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  19%|█▊        | 1500/8008 [05:00<19:48,  5.47it/s, loss=2.7959]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_1500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  19%|█▊        | 1501/8008 [05:08<4:44:43,  2.63s/it, loss=2.7959]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "only 3 drive backups found. no cleanup needed.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  25%|██▍       | 2000/8008 [06:40<18:17,  5.47it/s, loss=2.7951]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_2000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  25%|██▍       | 2001/8008 [06:55<7:47:37,  4.67s/it, loss=2.7951]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  31%|███       | 2500/8008 [08:27<16:47,  5.47it/s, loss=2.8023]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_2500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  31%|███       | 2501/8008 [08:38<5:22:13,  3.51s/it, loss=2.8023]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_1000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  37%|███▋      | 3000/8008 [10:10<15:11,  5.50it/s, loss=2.8020]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_3000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  37%|███▋      | 3001/8008 [12:16<52:35:57, 37.82s/it, loss=2.8020]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_1500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  44%|████▎     | 3500/8008 [13:47<13:49,  5.43it/s, loss=2.8083]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_3500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  44%|████▎     | 3501/8008 [15:53<47:15:07, 37.74s/it, loss=2.8083]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_2000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  50%|████▉     | 4000/8008 [17:25<12:12,  5.47it/s, loss=2.8070]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_4000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  50%|████▉     | 4001/8008 [19:31<42:23:44, 38.09s/it, loss=2.8070]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_2500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  56%|█████▌    | 4500/8008 [21:03<10:41,  5.47it/s, loss=2.8094]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_4500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  56%|█████▌    | 4501/8008 [23:09<37:04:46, 38.06s/it, loss=2.8094]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_3000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  62%|██████▏   | 5000/8008 [24:41<09:06,  5.51it/s, loss=2.8102]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_5000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  62%|██████▏   | 5001/8008 [26:54<33:32:11, 40.15s/it, loss=2.8102]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_3500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  69%|██████▊   | 5500/8008 [28:26<07:37,  5.48it/s, loss=2.8125]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_5500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  69%|██████▊   | 5501/8008 [30:41<28:17:18, 40.62s/it, loss=2.8125]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_4000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  75%|███████▍  | 6000/8008 [32:13<06:06,  5.48it/s, loss=2.8148]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_6000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  75%|███████▍  | 6001/8008 [34:22<21:38:56, 38.83s/it, loss=2.8148]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_4500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  81%|████████  | 6500/8008 [35:54<04:34,  5.49it/s, loss=2.8164]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_6500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  81%|████████  | 6501/8008 [38:00<15:55:39, 38.05s/it, loss=2.8164]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_5000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  87%|████████▋ | 7000/8008 [39:33<03:03,  5.48it/s, loss=2.8185]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_7000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  87%|████████▋ | 7001/8008 [41:41<10:48:20, 38.63s/it, loss=2.8185]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_5500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15:  94%|█████████▎| 7500/8008 [43:14<01:32,  5.47it/s, loss=2.8198]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_7500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15:  94%|█████████▎| 7501/8008 [45:25<5:34:00, 39.53s/it, loss=2.8198]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_6000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15: 100%|█████████▉| 8000/8008 [46:59<00:01,  5.46it/s, loss=2.8223]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_8000.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\repoch 15: 100%|█████████▉| 8001/8008 [49:23<05:04, 43.50s/it, loss=2.8223]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_6500\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "epoch 15: 100%|██████████| 8008/8008 [49:26<00:00,  2.70it/s, loss=2.8222]\n",
            "validation: 100%|██████████| 1001/1001 [00:47<00:00, 21.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 15 completed:\n",
            "  train loss: 2.8222\n",
            "  val loss: 2.9095\n",
            "  learning rate: 5.00e-05\n",
            "checkpoint saved to google drive: /content/drive/MyDrive/research_gap_backup_epoch_14_batch_8008.pt\n",
            "Mounted at /content/drive\n",
            "deleted old drive backup: epoch_14_batch_7000\n",
            "cleaned up 1 old drive backups. kept 3 most recent.\n",
            "Mounted at /content/drive\n",
            "epoch 14 trained model saved to drive: /content/drive/MyDrive/research_gap_epoch_14_model.pt\n",
            "training completed!\n",
            "Mounted at /content/drive\n",
            "final trained model saved to drive: /content/drive/MyDrive/research_gap_final_trained_model.pt\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Improved training completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Initializing the ResumeableTrainer with all the new components.\n",
        "improved_trainer = ResumeableTrainer(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    device=device,\n",
        "    checkpoint_dir='improved_checkpoints'\n",
        ")\n",
        "\n",
        "print(\"ResumeableTrainer initialized and ready for the improved training run.\")\n",
        "\n",
        "try:\n",
        "    print(\"\\nSTARTING IMPROVED TRAINING RUN\")\n",
        "\n",
        "    improved_trainer.run_complete_training(\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        TRAINING_CONFIG['num_epochs']\n",
        "    )\n",
        "    print(\"\\nImproved training completed successfully!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nTraining interrupted: {e}\")\n",
        "    print(\"Checkpoints have been saved. You can re-run this cell to resume.\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KvvKHL1YQ_zo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
